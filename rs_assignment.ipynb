{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "rs_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAQpYjPVzdsw",
        "colab_type": "text"
      },
      "source": [
        "# Recommendation Systems Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUjvLryBzdsx",
        "colab_type": "text"
      },
      "source": [
        "### MIE451/1513 UofT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8rWqpOEzdsz",
        "colab_type": "text"
      },
      "source": [
        "### Getting MovieLens data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQaV4DkBzds0",
        "colab_type": "text"
      },
      "source": [
        "* Download the movielens 100k dataset from this link: [ml-100k.zip](http://files.grouplens.org/datasets/movielens/ml-100k.zip)\n",
        "\n",
        "* Upload ml-100k.zip\n",
        "\n",
        "* Extract using the following cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9dHQTK1zds1",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xncf3xm1zds2",
        "colab_type": "code",
        "outputId": "28d607f8-6a93-42b8-a384-5a3f82e04e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import required libraries\n",
        "!pip install wget\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from heapq import nlargest\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import wget\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1ill6yOzds5",
        "colab_type": "text"
      },
      "source": [
        "## Support functions and variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNbQGMevzds8",
        "colab_type": "code",
        "outputId": "f1d885b0-dedd-443c-ab49-a00ad86f8a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "wget.download(\"https://github.com/MIE451-1513-2019/course-datasets/raw/master/ml-100k.zip\")\n",
        "!unzip ml-100k.zip\n",
        "MOVIELENS_DIR = \"ml-100k\""
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ml-100k.zip\n",
            "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emOWqsTGzdtB",
        "colab_type": "code",
        "outputId": "90884ffe-2f62-4a25-956a-6d4e159421e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls {MOVIELENS_DIR}"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\n",
            "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\n",
            "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k0-kPF7zdtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getData(folder_path, file_name):\n",
        "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
        "    return data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvqWuW5NzdtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rating_df = getData(MOVIELENS_DIR, 'u.data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RPCAd--22MQ",
        "colab_type": "code",
        "outputId": "13919513-e353-4e60-a5c1-36a376206bdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj1kPvP6ymiv",
        "colab_type": "code",
        "outputId": "2b9f2b9a-cb23-45ae-ed11-bdd17b853685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rating_df['rating'].unique()"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 2, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpmN2NrTzdtK",
        "colab_type": "code",
        "outputId": "58aa45f8-38ad-4218-e6b8-cfc4d588c5f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_users = len(rating_df.userID.unique())\n",
        "num_items = len(rating_df.itemID.unique())\n",
        "print(\"Number of users:\", num_users)\n",
        "print(\"Number of items:\", num_items)"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of items: 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQg7fW9SzdtO",
        "colab_type": "text"
      },
      "source": [
        "## Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLVaLm25zdtO",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiiG_0QfzdtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataPreprocessor(rating_df, num_users, num_items):\n",
        "    \"\"\"\n",
        "        INPUT: \n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
        "            num_row: int. number of users\n",
        "            num_col: int. number of items\n",
        "            \n",
        "        OUTPUT:\n",
        "            matrix: 2D numpy array. \n",
        "            \n",
        "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
        "            \n",
        "        NOTE 2: data can have more columns, but your function should ignore \n",
        "              additional columns.\n",
        "    \"\"\"\n",
        "    ########### your code goes here ###########\n",
        "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
        "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
        "      matrix[userID-1, itemID-1] = rating\n",
        "    \n",
        "    ###########         end         ###########\n",
        "    return matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6DxbgBmzdtS",
        "colab_type": "code",
        "outputId": "3be2d362-ab88-44d7-b855-cee14e085ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "dataPreprocessor(rating_df, num_users, num_items)"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 3, 4, ..., 0, 0, 0],\n",
              "       [4, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [5, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b4XZHBczdtU",
        "colab_type": "text"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9AkrRvUzdtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseLineRecSys(object):\n",
        "    def __init__(self, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            method: string. From ['popularity','useraverage']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.method_name\n",
        "        \n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'popularity': self.popularity,\n",
        "            'useraverage': self.useraverage,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def useraverage(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "                \n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'    \n",
        "        \"\"\"\n",
        "        \n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "        # Initialize the predicted rating matrix with zeros\n",
        "    \n",
        "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
        "        # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "          if rating == 0:\n",
        "            # select the row for user\n",
        "            # what's the shape of userVector\n",
        "            userVector = train_matrix[user, :]\n",
        "            \n",
        "            # Extract the items the user already rated\n",
        "            ratedItems = userVector[userVector.nonzero()]\n",
        "            \n",
        "            # If not empty, calculate average and set as rating for the current item\n",
        "            if ratedItems.size == 0:\n",
        "                itemAvg = 0\n",
        "            else:\n",
        "                itemAvg = ratedItems.mean()\n",
        "            predictionMatrix[user, item] = itemAvg\n",
        "            \n",
        "        # report progress every 100 users\n",
        "        if (user % 100 == 0 and item == 1):\n",
        "            print (\"calculated %d users\" % (user,))\n",
        "\n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def popularity(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "                \n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
        "        \"\"\"\n",
        "        \n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "        # Initialize the predicted rating matrix with zeros\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
        "        itemPopularity = np.zeros((num_items))\n",
        "        for item in range(num_items):\n",
        "            numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
        "            numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
        "            if numOfUsersRated == 0:\n",
        "                itemPopularity[item] = 0\n",
        "            else:\n",
        "                itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
        "\n",
        "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
        "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "            if rating == 0:\n",
        "                predictionMatrix[user, item] = itemPopularity[item]\n",
        "\n",
        "            # report progress every 100 users\n",
        "            if (user % 100 == 0 and item == 1):\n",
        "                print (\"calculated %d users\" % (user,))\n",
        "\n",
        "                \n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix    \n",
        "    \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        self.__model = self.method(train_matrix, num_users, num_items)\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "            \n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "\n",
        "        return prediction\n",
        "        \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.model = None\n",
        "        except:\n",
        "            print(\"You don not have model..\")\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgDw3ALnzdtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "popularity_recsys = BaseLineRecSys('popularity')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJd50FSdzdta",
        "colab_type": "code",
        "outputId": "614daea4-bba5-4e48-b00c-3fbd6ace8bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "popularity_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5TJkUaszdtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = popularity_recsys.getModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN8r3Obtzdtg",
        "colab_type": "code",
        "outputId": "c4d9a2a0-e0e1-48d9-de52-932b4c7c205b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.all(x<=1)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZDsDg5Gzdtj",
        "colab_type": "code",
        "outputId": "c20458ef-a96c-42ca-f0f6-19d653b90573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p60BEmn-zdtm",
        "colab_type": "code",
        "outputId": "b609123f-c62f-477f-8df8-79b5c7f67e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "popularity_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30465it [00:27, 1106.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-255-1d1f62f9b708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpopularity_recsys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-249-1dee85571e04>\u001b[0m in \u001b[0;36mevaluate_test\u001b[0;34m(self, test_df, copy)\u001b[0m\n\u001b[1;32m    121\u001b[0m              \u001b[0muserID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m              itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_column_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserID\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemID\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    555\u001b[0m                 \u001b[0;31m# scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m                     \u001b[0msetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36msetter\u001b[0;34m(item, v)\u001b[0m\n\u001b[1;32m    487\u001b[0m                     \u001b[0;31m# set the item, possibly having a dtype change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5995\u001b[0m         \"\"\"\n\u001b[1;32m   5996\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5997\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__copy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSparseSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_pandas_abc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDu_THj3zdtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_user_rating_recsys = BaseLineRecSys('useraverage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQWmspQGzdtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_user_rating_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl8uLyIqzdty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_user_rating_recsys.getModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arSCkkxozdt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_user_rating_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_RlOlrIzdt7",
        "colab_type": "text"
      },
      "source": [
        "## Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4zY0XYDzdt7",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEQ_IkS3zdt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimBasedRecSys(object):\n",
        "\n",
        "    def __init__(self, base, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
        "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.base = base\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.base+'-'+self.method_name\n",
        "    \n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'cosine': self.cosine,\n",
        "            'euclidean': self.euclidean,\n",
        "            'somethingelse': self.somethingelse,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def cosine(matrix):\n",
        "        \"\"\"\n",
        "            cosine similarity\n",
        "        \"\"\"\n",
        "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def euclidean(matrix):\n",
        "        \"\"\"\n",
        "            euclidean similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "\n",
        "        similarity_matrix = 1 - pairwise_distances(matrix, metric='euclidean')\n",
        "    \n",
        "        ###########         end         ###########    \n",
        "        \n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def somethingelse(matrix):\n",
        "        \"\"\"\n",
        "            manhattan? or super-natural intuition similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "    \n",
        "        similarity_matrix = 1 - pairwise_distances(matrix, metric='manhattan')\n",
        "    \n",
        "    \n",
        "        ###########         end         ###########        \n",
        "        return similarity_matrix\n",
        "   \n",
        "    \n",
        "        \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT: \n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_row: scalar. number of users\n",
        "                num_col: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method assigns the result to self.model\n",
        "            \n",
        "            NOTES:\n",
        "                self.__model should contain predictions for *all* user and items\n",
        "                (don't worry about predicting for observed (user,item) pairs,\n",
        "                 since we won't be using these predictions in the evaluation)\n",
        "                (see code in for an efficient vectorized example)\n",
        "        \"\"\"\n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        if self.base == 'user':\n",
        "            ########### your code goes here ###########\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            uu_similarity = self.method(train_matrix)\n",
        "            # UxI: UxU mul UxI\n",
        "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
        "            #print(normalizer)\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            #what's the dimension of np.matmul(uu_similarity, trainSet)\n",
        "            \n",
        "            self.__model = np.matmul(uu_similarity, train_matrix)/normalizer\n",
        "            ###########         end         ###########\n",
        "            \n",
        "        elif self.base == 'item':\n",
        "            ########### your code goes here ###########\n",
        "            train_matrix = np.transpose(train_matrix)\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            ii_similarity = self.method(train_matrix)\n",
        "            # UxI: UxU mul UxI\n",
        "            normalizer = np.matmul(ii_similarity, temp_matrix)\n",
        "            #print(normalizer)\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            #what's the dimension of np.matmul(uu_similarity, trainSet)\n",
        "            \n",
        "            self.__model = np.transpose(np.matmul(ii_similarity, train_matrix)/normalizer)\n",
        "            ###########         end         ###########\n",
        "        else:\n",
        "            print('No other option available')\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                              \n",
        "            NOTE: 1. data can have more columns, but your function should ignore \n",
        "                  additional columns.\n",
        "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
        "                  if base == 'user' and method == 'cosine', \n",
        "                  then base-method == 'user-cosine'\n",
        "                  3. your predictions go to 'base-method' column\n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.model = None\n",
        "        except:\n",
        "            print(\"You do not have model..\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RROHVWRpzduA",
        "colab_type": "code",
        "outputId": "1064fde2-caf7-4eb3-a3eb-f5098947ab4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Examples of how to call similarity functions.\n",
        "I = np.eye(3)\n",
        "SimBasedRecSys.cosine(I)"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ5BkzGPzduC",
        "colab_type": "code",
        "outputId": "c503df44-64f2-4ff0-fb9e-f1d1f8ea3812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "SimBasedRecSys.euclidean(I)"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.41421356, -0.41421356],\n",
              "       [-0.41421356,  1.        , -0.41421356],\n",
              "       [-0.41421356, -0.41421356,  1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V-L-T-PzduF",
        "colab_type": "code",
        "outputId": "07529273-733d-4846-d333-e7a9a9835dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "SimBasedRecSys.somethingelse(I)"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1., -1., -1.],\n",
              "       [-1.,  1., -1.],\n",
              "       [-1., -1.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lktGjq0d3bbR",
        "colab_type": "text"
      },
      "source": [
        "The cosine is better than euclidean because in the case that two vectors have same direction but different length, cosine will return 1, which means they are the same, while euclidean will return the difference of their length, which is not very applicable in the situation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USPsbXpnzduH",
        "colab_type": "text"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBMIUTW74Mf7",
        "colab_type": "text"
      },
      "source": [
        "The manhattan penalize the ones that are different with L1-Norm, which could help the situation with L1 normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDrJogepzduL",
        "colab_type": "text"
      },
      "source": [
        "## Q3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ju9mZE9zduM",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAaSIC3BzduM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_cosine_recsys = SimBasedRecSys('user','cosine')\n",
        "item_cosine_recsys = SimBasedRecSys('item','cosine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBGVr2_JzduQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_cosine_recsys.predict_all(rating_df, num_users, num_items)\n",
        "item_cosine_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isW4B7nfzduW",
        "colab_type": "code",
        "outputId": "3f1bbb5a-d0c1-4c01-bd7f-7454d919a2fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "user_cosine_recsys.getModel()"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.89911175, 3.19022667, 3.0261129 , ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.84034456, 3.17139889, 2.92626717, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.87104065, 3.12823798, 3.03250708, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       ...,\n",
              "       [3.90754645, 3.20227238, 3.05776201, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.91100649, 3.21591021, 2.98854017, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.91593122, 3.24268207, 3.08255897, ..., 0.        , 3.        ,\n",
              "        3.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdxjAZJrzdud",
        "colab_type": "code",
        "outputId": "e199c960-d431-460b-f4af-9add09c597ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yc2PgKylzdug",
        "colab_type": "code",
        "outputId": "a7b05d60-2b70-48df-e847-e5dacf676d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "user_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "96it [00:00, 959.18it/s]\u001b[A\n",
            "198it [00:00, 975.34it/s]\u001b[A\n",
            "304it [00:00, 998.71it/s]\u001b[A\n",
            "409it [00:00, 1010.82it/s]\u001b[A\n",
            "515it [00:00, 1025.00it/s]\u001b[A\n",
            "618it [00:00, 1024.01it/s]\u001b[A\n",
            "721it [00:00, 1023.47it/s]\u001b[A\n",
            "820it [00:00, 1012.92it/s]\u001b[A\n",
            "923it [00:00, 1015.59it/s]\u001b[A\n",
            "1021it [00:01, 997.51it/s]\u001b[A\n",
            "1122it [00:01, 998.81it/s]\u001b[A\n",
            "1224it [00:01, 1004.49it/s]\u001b[A\n",
            "1328it [00:01, 1014.85it/s]\u001b[A\n",
            "1435it [00:01, 1028.51it/s]\u001b[A\n",
            "1540it [00:01, 1032.79it/s]\u001b[A\n",
            "1645it [00:01, 1036.83it/s]\u001b[A\n",
            "1750it [00:01, 1039.86it/s]\u001b[A\n",
            "1854it [00:01, 1030.54it/s]\u001b[A\n",
            "1958it [00:01, 1031.61it/s]\u001b[A\n",
            "2065it [00:02, 1042.36it/s]\u001b[A\n",
            "2170it [00:02, 1040.75it/s]\u001b[A\n",
            "2279it [00:02, 1053.60it/s]\u001b[A\n",
            "2388it [00:02, 1063.51it/s]\u001b[A\n",
            "2495it [00:02, 1063.36it/s]\u001b[A\n",
            "2602it [00:02, 1061.99it/s]\u001b[A\n",
            "2710it [00:02, 1065.97it/s]\u001b[A\n",
            "2817it [00:02, 1063.41it/s]\u001b[A\n",
            "2926it [00:02, 1070.24it/s]\u001b[A\n",
            "3034it [00:02, 1056.07it/s]\u001b[A\n",
            "3140it [00:03, 1039.35it/s]\u001b[A\n",
            "3245it [00:03, 1031.21it/s]\u001b[A\n",
            "3349it [00:03, 1032.72it/s]\u001b[A\n",
            "3454it [00:03, 1037.70it/s]\u001b[A\n",
            "3558it [00:03, 1035.21it/s]\u001b[A\n",
            "3662it [00:03, 1026.45it/s]\u001b[A\n",
            "3768it [00:03, 1035.61it/s]\u001b[A\n",
            "3876it [00:03, 1046.48it/s]\u001b[A\n",
            "3982it [00:03, 1049.52it/s]\u001b[A\n",
            "4087it [00:03, 1036.57it/s]\u001b[A\n",
            "4192it [00:04, 1038.76it/s]\u001b[A\n",
            "4296it [00:04, 1036.63it/s]\u001b[A\n",
            "4400it [00:04, 1036.03it/s]\u001b[A\n",
            "4504it [00:04, 1029.54it/s]\u001b[A\n",
            "4607it [00:04, 1022.52it/s]\u001b[A\n",
            "4711it [00:04, 1026.56it/s]\u001b[A\n",
            "4814it [00:04, 1026.09it/s]\u001b[A\n",
            "4919it [00:04, 1033.07it/s]\u001b[A\n",
            "5024it [00:04, 1037.48it/s]\u001b[A\n",
            "5128it [00:04, 1015.75it/s]\u001b[A\n",
            "5233it [00:05, 1023.41it/s]\u001b[A\n",
            "5338it [00:05, 1030.04it/s]\u001b[A\n",
            "5443it [00:05, 1034.51it/s]\u001b[A\n",
            "5547it [00:05, 1035.20it/s]\u001b[A\n",
            "5651it [00:05, 1033.34it/s]\u001b[A\n",
            "5756it [00:05, 1036.14it/s]\u001b[A\n",
            "5863it [00:05, 1045.24it/s]\u001b[A\n",
            "5968it [00:05, 1020.42it/s]\u001b[A\n",
            "6071it [00:05, 1022.57it/s]\u001b[A\n",
            "6174it [00:05, 1011.89it/s]\u001b[A\n",
            "6279it [00:06, 1021.34it/s]\u001b[A\n",
            "6385it [00:06, 1030.29it/s]\u001b[A\n",
            "6492it [00:06, 1039.09it/s]\u001b[A\n",
            "6596it [00:06, 1016.09it/s]\u001b[A\n",
            "6698it [00:06, 1017.01it/s]\u001b[A\n",
            "6806it [00:06, 1034.43it/s]\u001b[A\n",
            "6915it [00:06, 1048.39it/s]\u001b[A\n",
            "7022it [00:06, 1054.41it/s]\u001b[A\n",
            "7130it [00:06, 1059.53it/s]\u001b[A\n",
            "7237it [00:06, 1029.52it/s]\u001b[A\n",
            "7341it [00:07, 1031.27it/s]\u001b[A\n",
            "7446it [00:07, 1035.23it/s]\u001b[A\n",
            "7551it [00:07, 1038.54it/s]\u001b[A\n",
            "7656it [00:07, 1039.53it/s]\u001b[A\n",
            "7761it [00:07, 1041.40it/s]\u001b[A\n",
            "7867it [00:07, 1044.93it/s]\u001b[A\n",
            "7975it [00:07, 1054.02it/s]\u001b[A\n",
            "8081it [00:07, 1051.54it/s]\u001b[A\n",
            "8187it [00:07, 1044.42it/s]\u001b[A\n",
            "8292it [00:08, 1025.04it/s]\u001b[A\n",
            "8395it [00:08, 978.98it/s] \u001b[A\n",
            "8504it [00:08, 1008.23it/s]\u001b[A\n",
            "8607it [00:08, 1012.08it/s]\u001b[A\n",
            "8713it [00:08, 1025.73it/s]\u001b[A\n",
            "8823it [00:08, 1044.44it/s]\u001b[A\n",
            "8934it [00:08, 1061.71it/s]\u001b[A\n",
            "9045it [00:08, 1074.81it/s]\u001b[A\n",
            "9156it [00:08, 1083.91it/s]\u001b[A\n",
            "9267it [00:08, 1090.71it/s]\u001b[A\n",
            "9377it [00:09, 1060.66it/s]\u001b[A\n",
            "9485it [00:09, 1065.05it/s]\u001b[A\n",
            "9593it [00:09, 1067.65it/s]\u001b[A\n",
            "9700it [00:09, 1061.71it/s]\u001b[A\n",
            "9807it [00:09, 1058.65it/s]\u001b[A\n",
            "9913it [00:09, 1053.22it/s]\u001b[A\n",
            "10019it [00:09, 1043.13it/s]\u001b[A\n",
            "10125it [00:09, 1046.16it/s]\u001b[A\n",
            "10230it [00:09, 1040.75it/s]\u001b[A\n",
            "10335it [00:09, 1038.11it/s]\u001b[A\n",
            "10439it [00:10, 1021.27it/s]\u001b[A\n",
            "10545it [00:10, 1031.50it/s]\u001b[A\n",
            "10652it [00:10, 1042.17it/s]\u001b[A\n",
            "10759it [00:10, 1049.80it/s]\u001b[A\n",
            "10865it [00:10, 1051.70it/s]\u001b[A\n",
            "10971it [00:10, 1047.47it/s]\u001b[A\n",
            "11077it [00:10, 1050.33it/s]\u001b[A\n",
            "11183it [00:10, 1042.24it/s]\u001b[A\n",
            "11290it [00:10, 1049.08it/s]\u001b[A\n",
            "11397it [00:10, 1054.70it/s]\u001b[A\n",
            "11503it [00:11, 1033.36it/s]\u001b[A\n",
            "11609it [00:11, 1040.87it/s]\u001b[A\n",
            "11717it [00:11, 1050.80it/s]\u001b[A\n",
            "11823it [00:11, 1051.61it/s]\u001b[A\n",
            "11930it [00:11, 1054.60it/s]\u001b[A\n",
            "12036it [00:11, 1046.49it/s]\u001b[A\n",
            "12142it [00:11, 1047.67it/s]\u001b[A\n",
            "12248it [00:11, 1051.12it/s]\u001b[A\n",
            "12354it [00:11, 1040.70it/s]\u001b[A\n",
            "12459it [00:11, 1037.91it/s]\u001b[A\n",
            "12563it [00:12, 1012.06it/s]\u001b[A\n",
            "12668it [00:12, 1021.52it/s]\u001b[A\n",
            "12773it [00:12, 1029.10it/s]\u001b[A\n",
            "12878it [00:12, 1034.40it/s]\u001b[A\n",
            "12984it [00:12, 1039.48it/s]\u001b[A\n",
            "13089it [00:12, 1042.11it/s]\u001b[A\n",
            "13195it [00:12, 1045.63it/s]\u001b[A\n",
            "13300it [00:12, 1046.13it/s]\u001b[A\n",
            "13405it [00:12, 1045.36it/s]\u001b[A\n",
            "13511it [00:13, 1049.35it/s]\u001b[A\n",
            "13616it [00:13, 1031.55it/s]\u001b[A\n",
            "13720it [00:13, 1032.53it/s]\u001b[A\n",
            "13826it [00:13, 1039.22it/s]\u001b[A\n",
            "13931it [00:13, 1041.81it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-265-b78a55134cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_cosine_recsys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-257-95d44234bb4d>\u001b[0m in \u001b[0;36mevaluate_test\u001b[0;34m(self, test_df, copy)\u001b[0m\n\u001b[1;32m    132\u001b[0m              \u001b[0muserID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m              itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_column_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserID\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemID\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;31m# if we have a partial multiindex, then need to adjust the plane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# indexer here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2971\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2972\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2973\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2975\u001b[0m         \u001b[0;31m# Do we have a slicer (on rows)?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3268\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3270\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3271\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3272\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_new\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_isna_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlibmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecknull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# hack (for now) because MI registers as ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ic_FKWUzdui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZdTvp_szduk",
        "colab_type": "text"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-BnXbsLzdul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CrossValidation(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items retrived\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "    \n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "    \n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "    \n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "    \n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "            \n",
        "        return matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms. \n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJKyb9l-zdun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How to use CrossValidation Class?\n",
        "user_cosine_recsys = SimBasedRecSys('user','cosine')\n",
        "item_cosine_recsys = SimBasedRecSys('item','cosine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU3rZPtnzdus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. gather your algorithms in previous steps.\n",
        "algorithm_instances = [item_cosine_recsys, \n",
        "                       user_cosine_recsys]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf-m7d5Dzdux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
        "# RMSE, P@K, R@K\n",
        "# Precision at K in this example\n",
        "cv_patk = CrossValidation('RMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqcihyZdzduz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. Run CV by giving:\n",
        "#    1> algorithms just gathered\n",
        "#    2> number of users in the full dataset\n",
        "#    3> number of items in the full dataset\n",
        "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
        "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
        "cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liVfdNIpoioY",
        "colab_type": "text"
      },
      "source": [
        "The user based performs better because the average rating per user is higher than average rating per item due to #item > #user. And with more information the prediction can be better and more stable. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCFpLY25JuY",
        "colab_type": "text"
      },
      "source": [
        "## Q4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMdW5aLG5OTH",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI1hS4CP5RVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PMFRecSys(object):\n",
        "    def __init__(self, num_feat=10, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
        "        \"\"\"\n",
        "            num_feat: int, number of latent features\n",
        "            epsilon: float, learning rate\n",
        "            _lambda: float, L2 regularization,\n",
        "            momentum: float, momentum of the gradient,\n",
        "            maxepoch: float, Number of epoch before stop,\n",
        "            num_batches: int, Number of batches in each epoch (for SGD optimization),\n",
        "            batch_size:Number int, of training samples used in each batches (for SGD optimization)\n",
        "            \n",
        "        \"\"\"\n",
        "        self.num_feat = num_feat  # Number of latent features,\n",
        "        self.epsilon = epsilon  # learning rate,\n",
        "        self._lambda = _lambda  # L2 regularization,\n",
        "        self.momentum = momentum  # momentum of the gradient,\n",
        "        self.maxepoch = maxepoch  # Number of epoch before stop, #number of iteration over train data to learn it better\n",
        "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
        "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
        "        self.test = False\n",
        "        self.w_Item = None  # Item feature vectors\n",
        "        self.w_User = None  # User feature vectors\n",
        "        \n",
        "        self.rmse_train = []\n",
        "        self.rmse_test = []\n",
        "        self.pred_column_name='PMF'\n",
        "\n",
        "    def predict_all(self, train_vec, num_user, num_item):\n",
        "        \"\"\"\n",
        "            INPUT: \n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_user: scalar. number of users\n",
        "                num_item: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method update w_User and w_Item\n",
        "            \n",
        "            NOTES:\n",
        "                self.W_Item and self.W_User are use to do the final predition for a user\n",
        "                \n",
        "        \"\"\"\n",
        "        # select 'userID', 'itemID', 'rating only\n",
        "        train_vec = train_vec.iloc[:, :3].values\n",
        "        if self.test:\n",
        "          train_vec, val_vec = train_test_split(train_vec)\n",
        "          pairs_val = val_vec.shape[0]\n",
        "          self.mean_rating_test = np.mean(val_vec[:, 2])\n",
        "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating\n",
        "        pairs_train = train_vec.shape[0]  # num of rating\n",
        "        \n",
        "\n",
        "        # to avoid out of bound\n",
        "        num_user += 1  \n",
        "        num_item += 1  \n",
        "        # initialize\n",
        "        self.epoch = 0\n",
        "        \n",
        "        ########### your code goes here ###########\n",
        "\n",
        "        self.w_Item = sqrt(0.1) * np.random.randn(num_item, self.num_feat)  # item M x D \n",
        "        self.w_User = sqrt(0.1) * np.random.randn(num_user, self.num_feat)  # user N x D \n",
        "    \n",
        "    \n",
        "        ###########         end         ###########  \n",
        "\n",
        "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
        "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
        "        while self.epoch < self.maxepoch: \n",
        "            self.epoch += 1\n",
        "\n",
        "            # Shuffle training truples\n",
        "            shuffled_order = np.arange(train_vec.shape[0])  \n",
        "            np.random.shuffle(shuffled_order)  #shuffled\n",
        "\n",
        "            # Batch update\n",
        "            for batch in range(self.num_batches): \n",
        "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
        "\n",
        "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1))\n",
        "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index\n",
        "\n",
        "\n",
        "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
        "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating  \n",
        "                ########### your code goes here ###########\n",
        "            \n",
        "                pred_out = np.sum(np.multiply(self.w_User[batch_UserID, :],\\\n",
        "                                       self.w_Item[batch_ItemID, :]), axis = 1) #size (batch_size, )\n",
        "            \n",
        "            \n",
        "                ###########         end         ########### \n",
        "\n",
        "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
        "\n",
        "                # Compute gradients\n",
        "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
        "                       + self._lambda * self.w_User[batch_UserID, :]\n",
        "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
        "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
        "\n",
        "                dw_Item = np.zeros((num_item, self.num_feat))\n",
        "                dw_User = np.zeros((num_user, self.num_feat))\n",
        "\n",
        "                # loop to aggreate the gradients of the same element\n",
        "                for i in range(self.batch_size):\n",
        "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
        "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
        "\n",
        "                # Update with momentum\n",
        "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
        "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
        "\n",
        "                self.w_Item = self.w_Item - self.w_Item_inc\n",
        "                self.w_User = self.w_User - self.w_User_inc\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating \n",
        "                if batch == self.num_batches - 1:\n",
        "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
        "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(np.multiply(self.w_User[train_user_idx, :],\\\n",
        "                                       self.w_Item[train_item_idx, :]), axis = 1) # size(pairs_train, )\n",
        "            \n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2] \n",
        "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
        "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
        "\n",
        "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
        "\n",
        "                # Compute validation error\n",
        "                if batch == self.num_batches - 1 and self.test:\n",
        "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
        "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(np.multiply(self.w_User[val_user_idx, :],\\\n",
        "                                       self.w_Item[val_item_idx, :]), axis = 1) #size(pairs_val, )\n",
        "            \n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
        "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                              \n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
        "        else:\n",
        "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = (np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def plot_error(self):\n",
        "      if self.test:\n",
        "        plt.plot(range(pmf.maxepoch), pmf.rmse_test, marker='v', label='Test Data')\n",
        "      plt.plot(range(pmf.maxepoch), pmf.rmse_train, marker='o', label='Training Data')\n",
        "      plt.title('The MovieLens Dataset Learning Curve')\n",
        "      plt.xlabel('Number of Epochs')\n",
        "      plt.ylabel('RMSE')\n",
        "      plt.legend()\n",
        "      plt.grid()\n",
        "      plt.show()\n",
        "          \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.w_Item = None \n",
        "            self.w_User = None \n",
        "        except:\n",
        "            print(\"You do not have w_Item, w_User\")\n",
        "\n",
        "    def set_params(self, parameters):\n",
        "        if isinstance(parameters, dict):\n",
        "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
        "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
        "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
        "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
        "            self.maxepoch = parameters.get(\"maxepoch\", 20)\n",
        "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
        "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
        "            self.test = parameters.get(\"test_mode\", False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce7wlxycY76k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pmf = PMFRecSys()\n",
        "pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 100, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':True})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p56cFny7Y_Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pmf.predict_all(rating_df, num_users, num_items)\n",
        "pmf.plot_error()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tkSLeDqzdu1",
        "colab_type": "text"
      },
      "source": [
        "## Q5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00OSiRl9zdu2",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B3hHgZMsTN20",
        "colab": {}
      },
      "source": [
        "pmf = PMFRecSys()\n",
        "pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 20, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':False})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PtS4g-rtTN3C",
        "colab": {}
      },
      "source": [
        "algorithm_instances = [popularity_recsys,\n",
        "                       average_user_rating_recsys,\n",
        "                       item_cosine_recsys, \n",
        "                       user_cosine_recsys,\n",
        "                       pmf]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G9SltRlQTN3H",
        "colab": {}
      },
      "source": [
        "cv_patk = CrossValidation('P@K')\n",
        "cv_ratk = CrossValidation('R@K')\n",
        "cv_rmse = CrossValidation('RMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJyh9EsDXjME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_patk = cv_patk.run(algorithm_instances, num_users, num_items,k=5)\n",
        "result_ratk = cv_ratk.run(algorithm_instances, num_users, num_items,k=5)\n",
        "result_rmse = cv_rmse.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL_ZXAfJhQjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('P@K\\n------------------------------')\n",
        "for key, value in result_patk.items():\n",
        "  print ('%s \\t %f \\t %f \\t %f'% (key, value[1], value[2], value[3]))\n",
        "print('\\nR@K\\n------------------------------')\n",
        "for key, value in result_ratk.items():\n",
        "  print ('%s \\t %f \\t %f \\t %f'% (key, value[1], value[2], value[3]))  \n",
        "print('\\nRMSE\\n------------------------------')\n",
        "for key, value in result_rmse.items():\n",
        "  print ('%s \\t %f \\t %f \\t %f'% (key, value[1], value[2], value[3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ndWFEgUzdu4",
        "colab_type": "text"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVkW1WiI-_TN",
        "colab_type": "text"
      },
      "source": [
        "Popularity can not be evaluated by RMSE as the matrix is calculated by the dividing the liked user by all the user rated, the difference between true value and the number will be very large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FeYpBP5-_xi",
        "colab_type": "text"
      },
      "source": [
        "### (c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJuBdEzb_Dph",
        "colab_type": "text"
      },
      "source": [
        "For RMSE the best method is PMF. For P@K and R@K is user-cosine but the PMF performance is similar to user-cosine.\n",
        "\n",
        "PMF is good in most of the cases, because it calculate the prediction based on the U and V matrix with weighted scores to approximate the original matrix. And it has the ability to optimize performance along iterations and hyperparameter tuning. \n",
        "User-cosine similarity method is a very quick and common method and with the information from other users, its prediction ability is quite good and in this piticular situation, it is better than PMF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHYPXCVs_bGR",
        "colab_type": "text"
      },
      "source": [
        "### (d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rIpR7eI_eHN",
        "colab_type": "text"
      },
      "source": [
        "No, good RMSE means prediction is close to the true value and the system can be trusted to rank high similarity items high, but good ranking metrics without normalization sometimes cannot result in good RMSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkx8GW4wzdu8",
        "colab_type": "text"
      },
      "source": [
        "## Q6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnLcDctYzdu9",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_TFspr53XJV",
        "colab_type": "code",
        "outputId": "7807b3d9-c6aa-4bc9-c18b-c31915111505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# get item item similarity matrix\n",
        "item_matrix = np.transpose(dataPreprocessor(rating_df, num_users, num_items))\n",
        "ii_similarity = pd.DataFrame(pairwise_distances(item_matrix, metric='cosine'))\n",
        "\n",
        "# get movie data and select 3 movies\n",
        "movie_df = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', encoding='latin-1', header=None)\n",
        "print(movie_df[movie_df.iloc[:, 1].str.contains(\"Wild Things\")].iloc[:, :3])\n",
        "print(movie_df[movie_df.iloc[:, 1].str.contains(\"City of Angels\")].iloc[:, :3])\n",
        "print(movie_df[movie_df.iloc[:, 1].str.contains(\"Palmetto\")].iloc[:, :3])"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0                   1            2\n",
            "913  914  Wild Things (1998)  14-Mar-1998\n",
            "       0                                 1            2\n",
            "742  743  Crow: City of Angels, The (1996)  30-Aug-1996\n",
            "917  918             City of Angels (1998)  03-Apr-1998\n",
            "         0                1            2\n",
            "1312  1313  Palmetto (1998)  20-Feb-1998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzHmiBb1Lu6z",
        "colab_type": "code",
        "outputId": "aaf9d75e-57c2-4040-cba1-3f2fdf8eaee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# 3 movies index\n",
        "movies = [913, 917, 1312]\n",
        "for mov in movies:\n",
        "  top5 = np.argsort(ii_similarity.iloc[:, mov].drop(mov))[:5]\n",
        "  print(\"------------------------------------------\\n\")\n",
        "  print(movie_df.iloc[mov, 1],\"top 5 similar movies \\n\")\n",
        "  for m_i in top5:\n",
        "    print (movie_df.iloc[m_i, 1])"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------\n",
            "\n",
            "Wild Things (1998) top 5 similar movies \n",
            "\n",
            "Mercury Rising (1998)\n",
            "Primary Colors (1998)\n",
            "Lost in Space (1998)\n",
            "Wild Things (1998)\n",
            "Cérémonie, La (1995)\n",
            "------------------------------------------\n",
            "\n",
            "City of Angels (1998) top 5 similar movies \n",
            "\n",
            "Death in Brunswick (1991)\n",
            "Mercury Rising (1998)\n",
            "Young Guns II (1990)\n",
            "Heaven & Earth (1993)\n",
            "Wild Things (1998)\n",
            "------------------------------------------\n",
            "\n",
            "Palmetto (1998) top 5 similar movies \n",
            "\n",
            "Kaspar Hauser (1993)\n",
            "Pompatus of Love, The (1996)\n",
            "Winter Guest, The (1997)\n",
            "Apt Pupil (1998)\n",
            "Cobb (1994)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnRDOuH4zdvF",
        "colab_type": "text"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbJNC2XNMHB5",
        "colab_type": "text"
      },
      "source": [
        "The result makes some sense to an extend as the item based system will rank those movies rated by same or similar user high, and the user's taste and judgment standard on movie tend to keep same across movies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiSiG2UrzdvK",
        "colab_type": "text"
      },
      "source": [
        "## Q7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH63iq22zdvK",
        "colab_type": "text"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeUK2ZR5zdvM",
        "colab_type": "code",
        "outputId": "8e365ee7-c2c2-499f-f16a-3dbebd53f6dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "import scipy\n",
        "from matplotlib.pyplot import figure\n",
        "# user-iterm matrix\n",
        "u_i_matrix = dataPreprocessor(rating_df, num_users, num_items)\n",
        "# get the number of ratings for each user\n",
        "user = u_i_matrix.astype(bool).sum(axis=1)\n",
        "\n",
        "# plot\n",
        "figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "hist, bin_edges = scipy.histogram(user, bins=100)\n",
        "plt.bar(bin_edges[:-1], hist, width = 6) \n",
        "plt.xlim(0, max(bin_edges)) \n",
        "plt.show()"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGMCAYAAACRcHuiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naRoOO1MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5NexFtwo-fP",
        "colab_type": "code",
        "outputId": "809f367b-6599-461a-9e19-c4fdfe6f5112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "u_i_matrix[np.where(user>41)[0]]"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 3, 4, ..., 0, 0, 0],\n",
              "       [4, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZKOM9suABwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def useritermpred(train_matrix, base):\n",
        "  if base == 'user':\n",
        "    temp_matrix = np.zeros(train_matrix.shape)\n",
        "    temp_matrix[train_matrix.nonzero()] = 1\n",
        "    uu_similarity = 1 - pairwise_distances(train_matrix, metric='cosine')\n",
        "    # UxI: UxU mul UxI\n",
        "    normalizer = np.matmul(uu_similarity, temp_matrix)\n",
        "    #print(normalizer)\n",
        "    normalizer[normalizer == 0] = 1e-5\n",
        "    #what's the dimension of np.matmul(uu_similarity, trainSet)\n",
        "    \n",
        "    predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
        "    # if no one has rated this item before, use user average  \n",
        "    useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
        "    columns = np.sum(predictionMatrix, axis=0)\n",
        "    #print(columns.shape)\n",
        "    predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)  \n",
        "    return predictionMatrix\n",
        "\n",
        "    \n",
        "  elif base == 'item':\n",
        "    train_matrix = np.transpose(train_matrix)\n",
        "    temp_matrix = np.zeros(train_matrix.shape)\n",
        "    temp_matrix[train_matrix.nonzero()] = 1\n",
        "    ii_similarity = 1 - pairwise_distances(train_matrix, metric='cosine')\n",
        "    # UxI: UxU mul UxI\n",
        "    normalizer = np.matmul(ii_similarity, temp_matrix)\n",
        "    #print(normalizer)\n",
        "    normalizer[normalizer == 0] = 1e-5\n",
        "    #what's the dimension of np.matmul(uu_similarity, trainSet)\n",
        "    \n",
        "    predictionMatrix = np.matmul(ii_similarity, train_matrix)/normalizer\n",
        "    # if no one has rated this item before, use user average  \n",
        "    itemaverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
        "    columns = np.sum(predictionMatrix, axis=0)\n",
        "    #print(columns.shape)\n",
        "    predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)   \n",
        "    return np.transpose(predictionMatrix)\n",
        "\n",
        "  else:\n",
        "    print('No other option available')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "68af486e-28ce-4f4e-83e6-75a71b7ca5f9",
        "id": "8n0tACXZNMLd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "datasetsFileNames = [('u2.base', 'u2.test'),\n",
        "                     ('u3.base', 'u3.test'),\n",
        "                     ('u4.base', 'u4.test'),\n",
        "                     ('u5.base', 'u5.test')]\n",
        "rmseList = []\n",
        "\n",
        "def rmse(pred, test):\n",
        "    # calculate RMSE for all the items in the test dataset\n",
        "    predItems = pred[test.nonzero()].flatten() \n",
        "    testItems = test[test.nonzero()].flatten()\n",
        "    return sqrt(mean_squared_error(predItems, testItems))\n",
        "\n",
        "for trainFileName, testFileName in datasetsFileNames:\n",
        "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
        "    curTrainDF = pd.read_csv(os.path.join(MOVIELENS_DIR, trainFileName), sep='\\t', names=fields)\n",
        "    curTestDF = pd.read_csv(os.path.join(MOVIELENS_DIR, testFileName), sep='\\t', names=fields)\n",
        "    \n",
        "    curTrainUserItemMatrix = dataPreprocessor(curTrainDF, num_users, num_items)\n",
        "    curTestUserItemMatrix = dataPreprocessor(curTestDF, num_users, num_items)\n",
        "    \n",
        "    # overTrainDF = curTrainDF[curTrainDF['userID'].isin(np.where(user>41)[0])]\n",
        "    # underTrainDF = curTrainDF[curTrainDF['userID'].isin(np.where(user<=41)[0])]\n",
        "    # overTestDF = curTestDF[curTrainDF['userID'].isin(np.where(user>41)[0])]\n",
        "    # underTestDF = curTestDF[curTrainDF['userID'].isin(np.where(user<=41)[0])]\n",
        "\n",
        "    overTrainUserItemMatrix = curTrainUserItemMatrix[np.where(user>41)[0]]\n",
        "    overTestUserItemMatrix = curTestUserItemMatrix[np.where(user>41)[0]]\n",
        "    underTrainUserItemMatrix = curTrainUserItemMatrix[np.where(user<=41)[0]]\n",
        "    underTestUserItemMatrix = curTestUserItemMatrix[np.where(user<=41)[0]]\n",
        "\n",
        "    #prediction with user based\n",
        "    overUserSimPreiction = useritermpred(overTrainUserItemMatrix, 'user')\n",
        "    overUserRMSE = rmse(overUserSimPreiction, overTestUserItemMatrix)\n",
        "  \n",
        "    underUserSimPreiction = useritermpred(underTrainUserItemMatrix, 'user')\n",
        "    underUserRMSE = rmse(underUserSimPreiction, underTestUserItemMatrix)\n",
        "    \n",
        "    #prediction with similarity\n",
        "    overItemSimPreiction = useritermpred(overTrainUserItemMatrix, 'item')\n",
        "    overItemRMSE = rmse(curItemSimPreiction, overTestUserItemMatrix)\n",
        "    \n",
        "    underItemSimPreiction = useritermpred(underTrainUserItemMatrix, 'item')\n",
        "    underItemRMSE = rmse(underItemSimPreiction, underTestUserItemMatrix)\n",
        "    \n",
        "    rmseList.append(('above threshold user based', overUserRMSE, 'above threshold item based', overItemRMSE))\n",
        "    rmseList.append(('below threshold user based', underUserRMSE, 'below threshold item based', underItemRMSE))"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyPuDi-tPs7N",
        "colab_type": "code",
        "outputId": "b75f7a36-b062-4666-c066-fb213222e1e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for row in rmseList:\n",
        "  print(row)"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('above threshold user based', 1.0176177101131623, 'above threshold item based', 1.215993913182302)\n",
            "('below threshold user based', 1.1639298102974196, 'below threshold item based', 1.304806704799526)\n",
            "('above threshold user based', 1.0089233150255363, 'above threshold item based', 1.1964784723304804)\n",
            "('below threshold user based', 1.1687137360717321, 'below threshold item based', 1.328214626080602)\n",
            "('above threshold user based', 1.003060365970007, 'above threshold item based', 1.2086126103516175)\n",
            "('below threshold user based', 1.1594343260006608, 'below threshold item based', 1.34492772628239)\n",
            "('above threshold user based', 1.0133779056526728, 'above threshold item based', 1.2210697815956788)\n",
            "('below threshold user based', 1.1705993832588268, 'below threshold item based', 1.2734908167436738)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skqRP4ZaQ4fN",
        "colab_type": "text"
      },
      "source": [
        "Yes, there is difference.\n",
        "\n",
        "The system based on above threshold performs better than the ones based on below. It is because with average rating per user much higher, the information to predict a rating is much higher as well and hence, better prediction.\n",
        "\n",
        "The item based performs worse than user based as expected and the reason is explained in Q3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "G2V2BXb-zdvQ",
        "colab_type": "text"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjWEiRzezdvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants for validation only\n",
        "ROW_NUM = 943\n",
        "COL_NUM = 1682\n",
        "RATING_COL = 'rating'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqZ3DOSHzdvV",
        "colab_type": "text"
      },
      "source": [
        "### dataPreprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4jypcIRzdvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
        "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
        "    try:\n",
        "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    except:\n",
        "        print('dataPreprocessor function has error')\n",
        "        return\n",
        "    try:\n",
        "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return validation_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Tc_IVazdvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_df = validateDataPreprocessor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_PmoIrWzdvf",
        "colab_type": "text"
      },
      "source": [
        "## Baseline Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGA1yZ9hzdvf",
        "colab_type": "text"
      },
      "source": [
        "### Popularity Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ySapEazdvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    popularity_recsys = BaseLineRecSys('popularity')\n",
        "    try:\n",
        "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except Exception as e:        \n",
        "        print('popularity function has error')\n",
        "        print(e)\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = popularity_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyCJ1Be0zdvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc01412b-a6d5-42a2-907f-5c9eadb4532c"
      },
      "source": [
        "validatePopularityRecSys"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.validatePopularityRecSys>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g1wwQpxzdvp",
        "colab_type": "text"
      },
      "source": [
        "### User Average Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1KASm63zdvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    useraverage_recsys = BaseLineRecSys('useraverage')\n",
        "    try:\n",
        "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print('useraverage function has error')\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = useraverage_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A36VedIzdvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d02ae72b-e06a-40df-847d-06f16c806705"
      },
      "source": [
        "validatePopularityRecSys"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.validatePopularityRecSys>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlxJxooBzdvx",
        "colab_type": "text"
      },
      "source": [
        "## Similary Based Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvmIFAXXzdvy",
        "colab_type": "text"
      },
      "source": [
        "### Euclidean Similarity Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z74E1PMRzdvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqzEUppEzdv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validateEuclidean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnBQxFEPzdv6",
        "colab_type": "text"
      },
      "source": [
        "### Customized Similarity Function (test somethingelse function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPpRR_hjzdv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uGIWOS7zdv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validateCustomizedSim()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMKOOB6mzdwB",
        "colab_type": "text"
      },
      "source": [
        "### User-User Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_V0gdBTzdwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkausxHizdwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validateUUSimBasedRecSys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IAGUMvwzdwH",
        "colab_type": "text"
      },
      "source": [
        "### Item-Item Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-j6pDB3zdwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjAlZnpYzdwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validateIISimBasedRecSys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYo97yYTCKbI",
        "colab_type": "text"
      },
      "source": [
        "### Probabilistic Matrix Factorization Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB1_H8mxzdwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validatePMFRecSys(validation_df=validation_df):\n",
        "    try:\n",
        "        pmf = PMFRecSys()\n",
        "        pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 1, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':True})\n",
        "        pmf.predict_all(rating_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print(\"Got error when instantiate PMFRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        pmf.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        W_item, W_user = pmf.w_Item, pmf.w_User\n",
        "        assert(W_item.shape == (COL_NUM+1, 10) and W_user.shape == (ROW_NUM+1, 10)),\\\n",
        "        \"Shape of w_Item and W_User doesn't match predefined shape\"\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW82XMfdzdwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validatePMFRecSys(validation_df=validation_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldve7N_0DRF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}